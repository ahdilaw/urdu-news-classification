{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gGiWDmLopXO"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2df_TT_IopXR",
    "outputId": "e85253b3-11a2-443a-8fb6-e7f182853642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>local_id</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://urdu.arynews.tv/car-sales-in-pakistan/</td>\n",
       "      <td>پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ</td>\n",
       "      <td>ملکی آٹو سیکٹر سے زبردست خبر آگئی۔ پاکستان می...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://urdu.arynews.tv/gold-rates-in-pakistan-3/</td>\n",
       "      <td>پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟</td>\n",
       "      <td>کراچی: کاروباری ہفتے کے پہلے روز سونے کی قیمت ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://urdu.arynews.tv/cotton-production-cott...</td>\n",
       "      <td>امریکا سے معیاری روئی کی درآمد بڑھ گئی</td>\n",
       "      <td>کراچی: پاکستان میں کپاس کی پیداوار میں کمی کے ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>https://urdu.arynews.tv/psx-today-11-nov/</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج نے ایک اور سنگ میل عبور...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>https://urdu.arynews.tv/ghee-and-cooking-oil-p...</td>\n",
       "      <td>عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...</td>\n",
       "      <td>لاہور : گھی اور کوکنگ آئل کی قیمتوں میں ایک با...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>5939</td>\n",
       "      <td>492</td>\n",
       "      <td>https://jang.com.pk/news/1015053</td>\n",
       "      <td>کراچی یونیورسٹی نے ہاکی فائنل جیت لیا</td>\n",
       "      <td>ہائرایجوکیشن کمیشن (ایچ ای سی، زون جی ) ہاکی چ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>5940</td>\n",
       "      <td>495</td>\n",
       "      <td>https://jang.com.pk/news/1012389</td>\n",
       "      <td>قوم کو ایک بار پھر کرکٹ نے متحد کردیا</td>\n",
       "      <td>کئی سالوں کے بعد پہلی بار ایسا ہوا ہے کہ پاکست...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>5941</td>\n",
       "      <td>496</td>\n",
       "      <td>https://jang.com.pk/news/1012388</td>\n",
       "      <td>جامعہ این ای ڈی میں فلڈ لائٹ کرکٹ گراؤنڈ کا اف...</td>\n",
       "      <td>رواں ماہ ہر جانب ورلڈ کپ کی گہما گہمی جاری ہے،...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>5942</td>\n",
       "      <td>498</td>\n",
       "      <td>https://jang.com.pk/news/1012386</td>\n",
       "      <td>اسپورٹس مقابلے</td>\n",
       "      <td>الفا ایجوکیشن نیٹ ورک پر جہاں نصابی سرگرمیاں ب...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>5943</td>\n",
       "      <td>497</td>\n",
       "      <td>https://jang.com.pk/news/1012387</td>\n",
       "      <td>فٹبال ہاؤس سیل، صوبائی حکومت سے قانونی جنگ کری...</td>\n",
       "      <td>حکومت پنجا ب کی جانب سے لیز کی فیس جمع نہ کران...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5841 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  local_id                                               link  \\\n",
       "0        1         1     https://urdu.arynews.tv/car-sales-in-pakistan/   \n",
       "1        2         2  https://urdu.arynews.tv/gold-rates-in-pakistan-3/   \n",
       "2        3         5  https://urdu.arynews.tv/cotton-production-cott...   \n",
       "3        4         3          https://urdu.arynews.tv/psx-today-11-nov/   \n",
       "4        5         4  https://urdu.arynews.tv/ghee-and-cooking-oil-p...   \n",
       "...    ...       ...                                                ...   \n",
       "5938  5939       492                   https://jang.com.pk/news/1015053   \n",
       "5939  5940       495                   https://jang.com.pk/news/1012389   \n",
       "5940  5941       496                   https://jang.com.pk/news/1012388   \n",
       "5941  5942       498                   https://jang.com.pk/news/1012386   \n",
       "5942  5943       497                   https://jang.com.pk/news/1012387   \n",
       "\n",
       "                                                  title  \\\n",
       "0             پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ   \n",
       "1            پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟   \n",
       "2                امریکا سے معیاری روئی کی درآمد بڑھ گئی   \n",
       "3              پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم   \n",
       "4     عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...   \n",
       "...                                                 ...   \n",
       "5938              کراچی یونیورسٹی نے ہاکی فائنل جیت لیا   \n",
       "5939              قوم کو ایک بار پھر کرکٹ نے متحد کردیا   \n",
       "5940  جامعہ این ای ڈی میں فلڈ لائٹ کرکٹ گراؤنڈ کا اف...   \n",
       "5941                                     اسپورٹس مقابلے   \n",
       "5942  فٹبال ہاؤس سیل، صوبائی حکومت سے قانونی جنگ کری...   \n",
       "\n",
       "                                                content gold_label  \n",
       "0     ملکی آٹو سیکٹر سے زبردست خبر آگئی۔ پاکستان می...   Business  \n",
       "1     کراچی: کاروباری ہفتے کے پہلے روز سونے کی قیمت ...   Business  \n",
       "2     کراچی: پاکستان میں کپاس کی پیداوار میں کمی کے ...   Business  \n",
       "3     پاکستان اسٹاک ایکسچینج نے ایک اور سنگ میل عبور...   Business  \n",
       "4     لاہور : گھی اور کوکنگ آئل کی قیمتوں میں ایک با...   Business  \n",
       "...                                                 ...        ...  \n",
       "5938  ہائرایجوکیشن کمیشن (ایچ ای سی، زون جی ) ہاکی چ...     Sports  \n",
       "5939  کئی سالوں کے بعد پہلی بار ایسا ہوا ہے کہ پاکست...     Sports  \n",
       "5940  رواں ماہ ہر جانب ورلڈ کپ کی گہما گہمی جاری ہے،...     Sports  \n",
       "5941  الفا ایجوکیشن نیٹ ورک پر جہاں نصابی سرگرمیاں ب...     Sports  \n",
       "5942  حکومت پنجا ب کی جانب سے لیز کی فیس جمع نہ کران...     Sports  \n",
       "\n",
       "[5841 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "\n",
    "df = pd.read_csv('data/dataset.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "1jbQpNEhopXS",
    "outputId": "2d9b338a-ed39-4cf8-dcd5-526df67bc419"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>local_id</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://urdu.arynews.tv/car-sales-in-pakistan/</td>\n",
       "      <td>پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ</td>\n",
       "      <td>ملک آٹ سیکٹر س زبردست خبر آگئی۔ پاکستان گاڑی ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://urdu.arynews.tv/gold-rates-in-pakistan-3/</td>\n",
       "      <td>پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟</td>\n",
       "      <td>کراچ کاروبار ہفت پہل روز سون قیمت رجحان رہا۔ پ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://urdu.arynews.tv/cotton-production-cott...</td>\n",
       "      <td>امریکا سے معیاری روئی کی درآمد بڑھ گئی</td>\n",
       "      <td>کراچ پاکستان کپاس پیداوار باعث اسپننگ مل س معی...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>https://urdu.arynews.tv/psx-today-11-nov/</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج ن میل عبور لیا۔ کاروبار...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>https://urdu.arynews.tv/ghee-and-cooking-oil-p...</td>\n",
       "      <td>عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...</td>\n",
       "      <td>لاہور کوکنگ آئل قیمت اضاف ہوا، قمیت س تجاوز کر...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  local_id                                               link  \\\n",
       "0   1         1     https://urdu.arynews.tv/car-sales-in-pakistan/   \n",
       "1   2         2  https://urdu.arynews.tv/gold-rates-in-pakistan-3/   \n",
       "2   3         5  https://urdu.arynews.tv/cotton-production-cott...   \n",
       "3   4         3          https://urdu.arynews.tv/psx-today-11-nov/   \n",
       "4   5         4  https://urdu.arynews.tv/ghee-and-cooking-oil-p...   \n",
       "\n",
       "                                               title  \\\n",
       "0          پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ   \n",
       "1         پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟   \n",
       "2             امریکا سے معیاری روئی کی درآمد بڑھ گئی   \n",
       "3           پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم   \n",
       "4  عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...   \n",
       "\n",
       "                                             content gold_label  \n",
       "0  ملک آٹ سیکٹر س زبردست خبر آگئی۔ پاکستان گاڑی ...   Business  \n",
       "1  کراچ کاروبار ہفت پہل روز سون قیمت رجحان رہا۔ پ...   Business  \n",
       "2  کراچ پاکستان کپاس پیداوار باعث اسپننگ مل س معی...   Business  \n",
       "3  پاکستان اسٹاک ایکسچینج ن میل عبور لیا۔ کاروبار...   Business  \n",
       "4  لاہور کوکنگ آئل قیمت اضاف ہوا، قمیت س تجاوز کر...   Business  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add this function to perform stemming\n",
    "def simple_urdu_stemmer(word):\n",
    "    # Define common suffixes in Urdu\n",
    "    suffixes = ['یں', 'اں', 'وں', 'یں', 'ہاں', 'ی', 'ے', 'و', 'ہ']\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "# Loading Urdu stopwords from the json file\n",
    "with open('data/kaggle_stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    urdu_stopwords = set(json.load(file).keys())\n",
    "\n",
    "#Loading Shanzae Stopwords\n",
    "with open('data/shanzae/stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    shanzae_stopwords = set(json.load(file).keys())\n",
    "\n",
    "#Loading Yamsheen Stopwords\n",
    "with open('data/yamsheen/stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    yamsheen_stopwords = set(json.load(file).keys())\n",
    "\n",
    "# Function to clean our Urdu sentences\n",
    "def clean_content(text, stopwords):\n",
    "    # Remove punctuation and numbers\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    text = ' '.join(word for word in text.split() if word not in shanzae_stopwords)\n",
    "    text = ' '.join(word for word in text.split() if word not in yamsheen_stopwords)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    #Use the simple_urdu_stemmer\n",
    "    text = ' '.join(simple_urdu_stemmer(word) for word in text.split())\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: clean_content(x, urdu_stopwords))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Accuracy: 0.0000\n",
      "Epoch 10, Accuracy: 0.4713\n",
      "Epoch 20, Accuracy: 0.7571\n",
      "Epoch 30, Accuracy: 0.8440\n",
      "Epoch 40, Accuracy: 0.8744\n",
      "Epoch 50, Accuracy: 0.8889\n",
      "Epoch 60, Accuracy: 0.9015\n",
      "Epoch 70, Accuracy: 0.9105\n",
      "Epoch 80, Accuracy: 0.9178\n",
      "Epoch 90, Accuracy: 0.9259\n",
      "Epoch 100, Accuracy: 0.9313\n",
      "Epoch 110, Accuracy: 0.9351\n",
      "Epoch 120, Accuracy: 0.9399\n",
      "Epoch 130, Accuracy: 0.9435\n",
      "Epoch 140, Accuracy: 0.9486\n",
      "Epoch 150, Accuracy: 0.9510\n",
      "Epoch 160, Accuracy: 0.9542\n",
      "Epoch 170, Accuracy: 0.9580\n",
      "Epoch 180, Accuracy: 0.9595\n",
      "Epoch 190, Accuracy: 0.9617\n",
      "Epoch 200, Accuracy: 0.9647\n",
      "Epoch 210, Accuracy: 0.9645\n",
      "Epoch 220, Accuracy: 0.9658\n",
      "Epoch 230, Accuracy: 0.9673\n",
      "Epoch 240, Accuracy: 0.9694\n",
      "Epoch 250, Accuracy: 0.9705\n",
      "Epoch 260, Accuracy: 0.9730\n",
      "Epoch 270, Accuracy: 0.9726\n",
      "Epoch 280, Accuracy: 0.9747\n",
      "Epoch 290, Accuracy: 0.9767\n",
      "Epoch 300, Accuracy: 0.9795\n",
      "Epoch 310, Accuracy: 0.9797\n",
      "Epoch 320, Accuracy: 0.9801\n",
      "Epoch 330, Accuracy: 0.9807\n",
      "Epoch 340, Accuracy: 0.9831\n",
      "Epoch 350, Accuracy: 0.9844\n",
      "Epoch 360, Accuracy: 0.9839\n",
      "Epoch 370, Accuracy: 0.9846\n",
      "Epoch 380, Accuracy: 0.9846\n",
      "Epoch 390, Accuracy: 0.9852\n",
      "Epoch 400, Accuracy: 0.9850\n",
      "Epoch 410, Accuracy: 0.9848\n",
      "Epoch 420, Accuracy: 0.9846\n",
      "Epoch 430, Accuracy: 0.9859\n",
      "Epoch 440, Accuracy: 0.9844\n",
      "Epoch 450, Accuracy: 0.9848\n",
      "Epoch 460, Accuracy: 0.9872\n",
      "Epoch 470, Accuracy: 0.9848\n",
      "Epoch 480, Accuracy: 0.9859\n",
      "Epoch 490, Accuracy: 0.9846\n",
      "\n",
      "Neural Network Accuracy: 0.8656971770744226\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.85      0.85      0.85       188\n",
      "     Entertainment       0.95      0.94      0.94       225\n",
      "     International       0.81      0.80      0.80       225\n",
      "Science-Technology       0.93      0.89      0.91       257\n",
      "            Sports       0.97      0.97      0.97       274\n",
      "\n",
      "         micro avg       0.91      0.89      0.90      1169\n",
      "         macro avg       0.90      0.89      0.89      1169\n",
      "      weighted avg       0.91      0.89      0.90      1169\n",
      "       samples avg       0.88      0.89      0.88      1169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare the data\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Prepare labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform([[label] for label in df['gold_label']])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to dense arrays\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "class MultiLabelNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.layers_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(len(self.layers_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(self.layers_sizes[i], self.layers_sizes[i+1]) * np.sqrt(2./self.layers_sizes[i]))\n",
    "            self.biases.append(np.zeros((1, self.layers_sizes[i+1])))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            net = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.activations.append(self.sigmoid(net))\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        delta = output - y\n",
    "        \n",
    "        dWeights = []\n",
    "        dBiases = []\n",
    "        \n",
    "        for i in range(len(self.weights) - 1, -1, -1):\n",
    "            dW = np.dot(self.activations[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            \n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            \n",
    "            dWeights.insert(0, dW)\n",
    "            dBiases.insert(0, db)\n",
    "        \n",
    "        return dWeights, dBiases\n",
    "\n",
    "    def fit(self, X, y, epochs=100, batch_size=32, verbose=True):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Mini-batch gradient descent\n",
    "            indices = np.random.permutation(m)\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "            \n",
    "            for i in range(0, m, batch_size):\n",
    "                batch_X = X[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                \n",
    "                output = self.forward_propagation(batch_X)\n",
    "                dWeights, dBiases = self.backward_propagation(batch_X, batch_y, output)\n",
    "                \n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= self.learning_rate * dWeights[j]\n",
    "                    self.biases[j] -= self.learning_rate * dBiases[j]\n",
    "            \n",
    "            if verbose and epoch % 10 == 0:\n",
    "                predictions = self.predict(X)\n",
    "                accuracy = np.mean(np.all(predictions == y, axis=1))\n",
    "                print(f\"Epoch {epoch}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward_propagation(X)\n",
    "        return (output >= 0.5).astype(int)\n",
    "\n",
    "# Initialize and train the network\n",
    "input_size = X_train_dense.shape[1]\n",
    "hidden_sizes = [256, 128]\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "nn = MultiLabelNeuralNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    output_size=output_size,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "# Train\n",
    "nn.fit(X_train_dense, y_train, epochs=500, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = nn.predict(X_test_dense)\n",
    "print(\"\\nNeural Network Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new dataset: 0.5352591333899746\n",
      "\n",
      "Classification Report on new dataset:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.76      0.24      0.37       223\n",
      "     Entertainment       0.51      0.87      0.65       240\n",
      "     International       0.66      0.56      0.61       234\n",
      "Science-Technology       0.48      0.29      0.36       240\n",
      "            Sports       0.95      0.83      0.89       240\n",
      "\n",
      "         micro avg       0.64      0.56      0.60      1177\n",
      "         macro avg       0.67      0.56      0.57      1177\n",
      "      weighted avg       0.67      0.56      0.58      1177\n",
      "       samples avg       0.55      0.56      0.55      1177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the new dataset\n",
    "new_df = pd.read_csv('./data/bbc_dataset.csv')\n",
    "\n",
    "# Preprocess the content\n",
    "new_df['content'] = new_df['content'].apply(lambda x: clean_content(x, urdu_stopwords))\n",
    "\n",
    "# Transform the new data using the existing vectorizer\n",
    "X_new = vectorizer.transform(new_df['content'])\n",
    "\n",
    "# Convert to dense array\n",
    "X_new_dense = X_new.toarray()\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_new = nn.predict(X_new_dense)\n",
    "\n",
    "# If the new dataset has labels, evaluate the performance\n",
    "if 'gold_label' in new_df.columns:\n",
    "    # Prepare labels\n",
    "    new_df['gold_label'] = new_df['gold_label'].fillna('')\n",
    "    new_df['gold_label'] = new_df['gold_label'].str.split(',')\n",
    "    new_df['gold_label'] = new_df['gold_label'].apply(lambda x: [label.strip() for label in x if label.strip()])\n",
    "    y_new = mlb.transform(new_df['gold_label'])\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(\"Accuracy on new dataset:\", accuracy_score(y_new, y_pred_new))\n",
    "    print(\"\\nClassification Report on new dataset:\")\n",
    "    print(classification_report(y_new, y_pred_new, target_names=mlb.classes_))\n",
    "else:\n",
    "    # Convert predictions to labels\n",
    "    predicted_labels = mlb.inverse_transform(y_pred_new)\n",
    "\n",
    "    # Add predictions to the dataframe\n",
    "    new_df['predicted_labels'] = [';'.join(labels) for labels in predicted_labels]\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    new_df.to_csv('./data/dawn_dataset_predictions.csv', index=False)\n",
    "\n",
    "    # Display the predictions\n",
    "    print(new_df[['content', 'predicted_labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Accuracy: 0.0000\n",
      "Epoch 10, Accuracy: 0.4713\n",
      "Epoch 20, Accuracy: 0.7571\n",
      "Epoch 30, Accuracy: 0.8440\n",
      "Epoch 40, Accuracy: 0.8744\n",
      "Epoch 50, Accuracy: 0.8889\n",
      "Epoch 60, Accuracy: 0.9015\n",
      "Epoch 70, Accuracy: 0.9105\n",
      "Epoch 80, Accuracy: 0.9178\n",
      "Epoch 90, Accuracy: 0.9259\n",
      "Epoch 100, Accuracy: 0.9313\n",
      "Epoch 110, Accuracy: 0.9351\n",
      "Epoch 120, Accuracy: 0.9399\n",
      "Epoch 130, Accuracy: 0.9435\n",
      "Epoch 140, Accuracy: 0.9486\n",
      "Epoch 150, Accuracy: 0.9510\n",
      "Epoch 160, Accuracy: 0.9542\n",
      "Epoch 170, Accuracy: 0.9580\n",
      "Epoch 180, Accuracy: 0.9595\n",
      "Epoch 190, Accuracy: 0.9617\n",
      "Epoch 200, Accuracy: 0.9647\n",
      "Epoch 210, Accuracy: 0.9645\n",
      "Epoch 220, Accuracy: 0.9658\n",
      "Epoch 230, Accuracy: 0.9673\n",
      "Epoch 240, Accuracy: 0.9694\n",
      "Epoch 250, Accuracy: 0.9705\n",
      "Epoch 260, Accuracy: 0.9730\n",
      "Epoch 270, Accuracy: 0.9726\n",
      "Epoch 280, Accuracy: 0.9747\n",
      "Epoch 290, Accuracy: 0.9767\n",
      "Epoch 300, Accuracy: 0.9795\n",
      "Epoch 310, Accuracy: 0.9797\n",
      "Epoch 320, Accuracy: 0.9801\n",
      "Epoch 330, Accuracy: 0.9807\n",
      "Epoch 340, Accuracy: 0.9831\n",
      "Epoch 350, Accuracy: 0.9844\n",
      "Epoch 360, Accuracy: 0.9839\n",
      "Epoch 370, Accuracy: 0.9846\n",
      "Epoch 380, Accuracy: 0.9846\n",
      "Epoch 390, Accuracy: 0.9852\n",
      "Epoch 400, Accuracy: 0.9850\n",
      "Epoch 410, Accuracy: 0.9848\n",
      "Epoch 420, Accuracy: 0.9846\n",
      "Epoch 430, Accuracy: 0.9859\n",
      "Epoch 440, Accuracy: 0.9844\n",
      "Epoch 450, Accuracy: 0.9848\n",
      "Epoch 460, Accuracy: 0.9872\n",
      "Epoch 470, Accuracy: 0.9848\n",
      "Epoch 480, Accuracy: 0.9859\n",
      "Epoch 490, Accuracy: 0.9846\n",
      "\n",
      "Neural Network Accuracy: 0.8656971770744226\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.85      0.85      0.85       188\n",
      "     Entertainment       0.95      0.94      0.94       225\n",
      "     International       0.81      0.80      0.80       225\n",
      "Science-Technology       0.93      0.89      0.91       257\n",
      "            Sports       0.97      0.97      0.97       274\n",
      "\n",
      "         micro avg       0.91      0.89      0.90      1169\n",
      "         macro avg       0.90      0.89      0.89      1169\n",
      "      weighted avg       0.91      0.89      0.90      1169\n",
      "       samples avg       0.88      0.89      0.88      1169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare the data\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Prepare labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform([[label] for label in df['gold_label']])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to dense arrays\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "class MultiLabelNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.layers_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(len(self.layers_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(self.layers_sizes[i], self.layers_sizes[i+1]) * np.sqrt(2./self.layers_sizes[i]))\n",
    "            self.biases.append(np.zeros((1, self.layers_sizes[i+1])))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            net = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.activations.append(self.sigmoid(net))\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        delta = output - y\n",
    "        \n",
    "        dWeights = []\n",
    "        dBiases = []\n",
    "        \n",
    "        for i in range(len(self.weights) - 1, -1, -1):\n",
    "            dW = np.dot(self.activations[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            \n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            \n",
    "            dWeights.insert(0, dW)\n",
    "            dBiases.insert(0, db)\n",
    "        \n",
    "        return dWeights, dBiases\n",
    "\n",
    "    def fit(self, X, y, epochs=100, batch_size=32, verbose=True):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Mini-batch gradient descent\n",
    "            indices = np.random.permutation(m)\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "            \n",
    "            for i in range(0, m, batch_size):\n",
    "                batch_X = X[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                \n",
    "                output = self.forward_propagation(batch_X)\n",
    "                dWeights, dBiases = self.backward_propagation(batch_X, batch_y, output)\n",
    "                \n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= self.learning_rate * dWeights[j]\n",
    "                    self.biases[j] -= self.learning_rate * dBiases[j]\n",
    "            \n",
    "            if verbose and epoch % 10 == 0:\n",
    "                predictions = self.predict(X)\n",
    "                accuracy = np.mean(np.all(predictions == y, axis=1))\n",
    "                print(f\"Epoch {epoch}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward_propagation(X)\n",
    "        return (output >= 0.5).astype(int)\n",
    "\n",
    "# Initialize and train the network\n",
    "input_size = X_train_dense.shape[1]\n",
    "hidden_sizes = [256, 128]\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "nn = MultiLabelNeuralNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    output_size=output_size,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "# Train\n",
    "nn.fit(X_train_dense, y_train, epochs=500, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = nn.predict(X_test_dense)\n",
    "print(\"\\nNeural Network Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
